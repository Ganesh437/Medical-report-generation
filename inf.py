# -*- coding: utf-8 -*-
"""Inf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eiaigguJB7bjqtNHpEXK1g7AQxS-qn3a
"""

#remove warnings from displaying in output 
import warnings 
warnings.filterwarnings('ignore')

# importing the required libraries 
import os 
import re 
import nltk
import cv2
import time
import datetime
import pickle
nltk.download('stopwords')
nltk.download('punkt')
from bs4 import BeautifulSoup
from PIL import Image
from skimage.transform import resize
from nltk.corpus import stopwords
from nltk import word_tokenize
from os import listdir
from os import path
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns
from tqdm import tqdm
from wordcloud import WordCloud, ImageColorGenerator
from sklearn.model_selection import train_test_split
import nltk.translate.bleu_score as bleu
from google.colab.patches import cv2_imshow
from PIL import Image
import xml.etree.ElementTree as ET

import tensorflow as tf
tf.compat.v1.enable_eager_execution()
tf.keras.backend.clear_session()
from tensorflow.keras.models import Model
from tensorflow.keras.applications import densenet
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.applications.densenet import preprocess_input

from tensorflow.keras import layers 
import imgaug.augmenters as iaa
from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout
from tensorflow.keras.layers import LSTM,Embedding,Flatten,BatchNormalization,ReLU
from tensorflow.keras.layers import Softmax,RNN,Reshape,concatenate,TimeDistributed
import sys
sys.path.append('/content/drive/')
from inference import Encoder,Decoder
import inference

from google.colab import drive
drive.mount('/content/drive')

class output:
    def __init__(self):
        self.input_len_dec=123
        self.embedding_dim=256
        self.img_width=224
        self.img_height=224
        self.units = 512
        with open('tokenizer.pickle', 'rb') as handle:
            self.tokenizer = pickle.load(handle)
        self.target_vocab_size=len(self.tokenizer.word_index)+1
        self.image_features_extract_model = inference.get_image_feature_extract_model(self.img_width,self.img_height)
        self.encoder = Encoder(self.embedding_dim,self.image_features_extract_model)
        self.decoder = Decoder(self.target_vocab_size, self.embedding_dim, self.input_len_dec,self.units)
        self.encoder.build((1, 224, 224, 3))
        self.encoder.load_weights('/content/drive/MyDrive/weights/encoder.h5')
        inference.grader_decoder(self.decoder)
        self.decoder.load_weights('/content/drive/MyDrive/weights/decoder.h5')

    def load_image(self,image):
        img = tf.io.read_file(image)
        img = tf.image.decode_jpeg(img, channels=3)
        image = tf.image.resize(img, (int(self.img_height),int(self.img_width)))
        image = preprocess_input(image)
        return image

    def load_img(self,image_path):
        image_path = image_path.split(',')
        img1 = self.load_image('/content/drive/MyDrive/NLMCXR_png/'+image_path[0])
        img2 = self.load_image('/content/drive/MyDrive/NLMCXR_png/'+image_path[1])
        img1 = tf.expand_dims(img1, axis=0)
        img2 = tf.expand_dims(img2, axis=0)
        return (img1,img2)
    
    def predict(self,X):
        image_path = self.load_img(X)
        encoder_output_1 = self.encoder(image_path[0])
        encoder_output_2 = self.encoder(image_path[1])
        encoder_output = tf.keras.layers.Concatenate(axis=-1)([encoder_output_1,encoder_output_2])
        hidden = self.decoder.reset_hidden_state(batch_size=1)
        cell_state = self.decoder.reset_cell_state(batch_size=1)
        dec_input = tf.expand_dims([self.tokenizer.word_index['<start>']], 0)
        result = []

        for i in range(self.input_len_dec):
            predictions,hidden,attention_weights,cell_state=self.decoder.onestep_decoder(dec_input,hidden,encoder_output, cell_state)
            predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()
            result.append(self.tokenizer.index_word[predicted_id])
            if self.tokenizer.index_word[predicted_id] == '<end>':
                return ' '.join(result[:-1])

        dec_input = tf.expand_dims([predicted_id], 0)
        return ' '.join(result[:-1])

f = output()

f.predict('CXR3840_IM-1941-1001.png,CXR3840_IM-1941-2001.png')

f.predict('CXR575_IM-2173-2001.png,CXR575_IM-2173-1001.png')

f.predict('CXR600_IM-2192-2001.png,CXR600_IM-2192-1001.png')